{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siren Detection & Recognision in Real Time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdok\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "from keras.models import load_model\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 22050\n",
    "CHUNK = RATE * 3\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Siren Detection Model\n",
    "model_detection = load_model('Detection.h5')\n",
    "\n",
    "# Load the Siren Recognition Model\n",
    "model_recognition = tf.keras.models.load_model('Recognision.h5')\n",
    "\n",
    "# Butterworth bandpass filter parameters\n",
    "sos = signal.butter(5, [50, 5000], 'bandpass', fs=RATE, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 39, 129, 32)       160       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 19, 64, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 19, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 18, 63, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 9, 31, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 9, 31, 32)         0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 30, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 4, 15, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 4, 15, 64)         0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 3, 14, 64)         16448     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 1, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1, 7, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 64)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29122 (113.76 KB)\n",
      "Trainable params: 29122 (113.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_detection.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 80, 3)             42        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 40, 3)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 40, 16)            544       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 20, 16)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 16)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 909 (3.55 KB)\n",
      "Trainable params: 909 (3.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_recognition.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siren Detection Model Input Shape:  (40, 130, 1)\n",
      "Siren Recognition Model Input Shape:  (80, 1)\n"
     ]
    }
   ],
   "source": [
    "detection_input_shape = model_detection.input_shape[1:]\n",
    "recognition_input_shape = model_recognition.layers[0].input_shape[0][1:]\n",
    "\n",
    "print(\"Siren Detection Model Input Shape: \", detection_input_shape)\n",
    "print(\"Siren Recognition Model Input Shape: \", recognition_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function for Siren Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_detection(audio_data):\n",
    "    audio_data = signal.sosfilt(sos, audio_data)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=RATE, n_mfcc=40)\n",
    "    mfccs_padded = np.pad(mfccs, ((0, 0), (0, max(0, detection_input_shape[1] - mfccs.shape[1]))), mode='constant')\n",
    "    mfccs_padded = mfccs_padded.reshape(detection_input_shape)\n",
    "    mfccs_padded = np.expand_dims(mfccs_padded, axis=0)\n",
    "    return mfccs_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function for Siren Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_recognition(audio_data):\n",
    "    audio_data = audio_data[:RATE]\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=RATE, n_mfcc=80)\n",
    "    mfccs_scaled_features = np.mean(mfccs.T, axis=0)\n",
    "    mfccs_scaled_features = mfccs_scaled_features.reshape(recognition_input_shape)\n",
    "    mfccs_scaled_features = np.expand_dims(mfccs_scaled_features, axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time detection and recognition loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_detection_recognition():\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "    chosen_device_index = -1  # Adjust if necessary\n",
    "    for x in range(p.get_device_count()):\n",
    "        info = p.get_device_info_by_index(x)\n",
    "\n",
    "    # Open stream for real-time audio input\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input_device_index=chosen_device_index,\n",
    "                    input=True,\n",
    "                    output=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    Detection_Threshold = 0.5\n",
    "    while True:\n",
    "        # Read audio data from stream\n",
    "        data = stream.read(CHUNK)\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "        \n",
    "        # # Convert audio data to floating-point format\n",
    "        audio_data = audio_data.astype(np.float32) / 32767.0\n",
    "        audio_data = 2 * ((audio_data - min(audio_data)) / (max(audio_data) - min(audio_data))) - 1\n",
    "        \n",
    "        # Detect siren using detection model\n",
    "        prediction_feature = preprocess_detection(audio_data)\n",
    "        predicted_proba_vector = model_detection.predict(prediction_feature, verbose=0)\n",
    "        siren_prob = predicted_proba_vector[0][1]\n",
    "\n",
    "        # If siren is detected, perform recognition\n",
    "        if siren_prob > Detection_Threshold:\n",
    "            preprocessed_data_recognition = preprocess_recognition(audio_data)\n",
    "            predicted_class = np.argmax(model_recognition.predict(preprocessed_data_recognition, verbose=0)[0])\n",
    "            siren_type = {0: \"Ambulance\", 1: \"Firetruck\", 2: \"Traffic\"}[predicted_class]\n",
    "            print(f\"SIREN DETECTED! Type: {siren_type}\")\n",
    "        else:\n",
    "            print(f\"No siren detected, Certainty: {(siren_prob * 100):.2f}%\")\n",
    "\n",
    "    # Close the audio stream and PyAudio instance\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No siren detected, Certainty: 14.28%\n",
      "No siren detected, Certainty: 4.79%\n",
      "SIREN DETECTED! Type: Ambulance\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Ambulance\n",
      "SIREN DETECTED! Type: Ambulance\n",
      "SIREN DETECTED! Type: Firetruck\n",
      "SIREN DETECTED! Type: Ambulance\n",
      "SIREN DETECTED! Type: Ambulance\n",
      "Program terminated by user\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        real_time_detection_recognition()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Program terminated by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
